{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "recommendations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea0DbuOipCoE",
        "outputId": "77c16737-117f-4d11-e813-28de7734dca5"
      },
      "source": [
        "!pip install scann"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scann\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/14/ddc441a359e9947bb25befb86ec9c6f47d2d45cce7776ae20237cf9fd08d/scann-1.1.1-cp36-cp36m-manylinux2014_x86_64.whl (11.7MB)\n",
            "\u001b[K     |████████████████████████████████| 11.7MB 4.2MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scann) (1.19.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (2.4.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (1.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->scann) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (3.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (0.2.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->scann) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.3.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorflow, scann\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed scann-1.1.1 tensorflow-2.3.1 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8peE4o8_pCoF"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import scann"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hRj8slcxpCoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b152a1-24b0-422a-fb7a-c301ac2a6625"
      },
      "source": [
        "train = pd.read_csv(\"/content/data/SpotifyFeatures.csv\")\n",
        "train_df = train\n",
        "\n",
        "col_names = ['acousticness',\n",
        "               'danceability',\n",
        "               'energy',\n",
        "               'instrumentalness',\n",
        "               'liveness',\n",
        "               'loudness',\n",
        "               'speechiness',\n",
        "               'tempo',\n",
        "               'valence',\n",
        "               'popularity']\n",
        "train = train.drop_duplicates(col_names, keep='first')\n",
        "train = train[col_names]\n",
        "\n",
        "print(train.shape[0], train.shape[1])\n",
        "\n",
        "train_arr = train.to_numpy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "190959 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vVVhF7HipCoG"
      },
      "source": [
        "normalized_dataset = train_arr / np.linalg.norm(train_arr, axis=1)[:, np.newaxis]\n",
        "# configure ScaNN as a tree - asymmetric hash hybrid with reordering\n",
        "# anisotropic quantization as described in the paper; see README\n",
        "\n",
        "# use scann.scann_ops.build() to instead create a TensorFlow-compatible searcher\n",
        "searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").tree(\n",
        "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
        "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctAbiuKCpCoG",
        "outputId": "e0b49600-2edc-4254-b591-26f01c47d0b7"
      },
      "source": [
        "selected_song_index = 110961\n",
        "query_arr = train_arr[selected_song_index]\n",
        "\n",
        "# we have been exclusively calling batch search so far; the single-query call has the same API\n",
        "start = time.time()\n",
        "neighbors, distances = searcher.search(query_arr, final_num_neighbors=5)\n",
        "end = time.time()\n",
        "\n",
        "\n",
        "selected_song = [train_df.to_numpy()[selected_song_index][2], train_df.to_numpy()[selected_song_index][0]]\n",
        "songs=[]\n",
        "song_vector = [0,0,0,0,0,0,0,0,0,0]\n",
        "for index in neighbors:\n",
        "    song = train_df.to_numpy()[index]\n",
        "    songs_data = train_df[(train_df['artist_name'] == song[1]) & (train_df['track_name'] == song[2])]\n",
        "    song_info = [[song[1],song[2]]]\n",
        "    recommended_song_vector = [song[4], song[5], song[6],\n",
        "                        song[8], song[9], song[11], \n",
        "                        song[12], song[14], song[15],\n",
        "                        song[17]]\n",
        "    song_vector = [song_vector[i] + recommended_song_vector[i] for i in range(len(song_vector))]\n",
        "    for index, row in songs_data.iterrows():\n",
        "      song_info.append(row['genre']) \n",
        "    songs.append(song_info)\n",
        "\n",
        "song_vector = [song_vector[i]/5 for i in range(len(song_vector))]\n",
        "    \n",
        "print(selected_song)\n",
        "print(songs)\n",
        "\n",
        "print(\"Latency (ms):\", 1000*(end - start))\n",
        "\n",
        "print(song_vector/np.linalg.norm(song_vector))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Amazing', 'Pop']\n",
            "[[['Kanye West', 'Amazing'], 'Pop', 'Rap'], [['Flo Rida', 'Whistle'], 'Dance', 'Hip-Hop', 'Pop', 'Rap'], [['Machine Gun Kelly', 'LIVEFASTDIEYOUNG'], 'Hip-Hop', 'Rap'], [['Ellie Goulding', 'On My Mind'], 'R&B', 'Dance', 'Pop'], [['Adolphe Adam', 'Giselle / Act 1: No. 8a Final'], 'Opera']]\n",
            "Latency (ms): 0.40268898010253906\n",
            "[ 4.26406318e-01  2.71645907e-03  4.80334176e-03  4.47444453e-03\n",
            "  4.89174159e-04  1.02431577e-03 -7.68456298e-02  5.50252271e-04\n",
            "  9.01225430e-01  3.61410708e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw2U1DDQf20Z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYZrCIG8pCoH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}